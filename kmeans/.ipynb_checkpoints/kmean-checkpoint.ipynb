{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b533d042-e9bc-4940-b55a-cf94a6940bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"facebook/Live.csv\")\n",
    "\n",
    "# print(df.describe())\n",
    "# print(\"///////////////////////////\")\n",
    "# print(f'columns: ', df.columns)\n",
    "\n",
    "# valuse of columns\n",
    "\n",
    "# values = df['status_id']\n",
    "# print(f'values of status IDs: ', values.unique())\n",
    "\n",
    "# values = df['status_type']\n",
    "# print(f'values of status type: ', values.unique())\n",
    "#\n",
    "# values = df['status_published']\n",
    "# print(f'values of status_published: ', values.unique())\n",
    "#\n",
    "# values = df['num_reactions']\n",
    "# print(f'values of num_reactions: ', values.unique())\n",
    "#\n",
    "# values = df['num_comments']\n",
    "# print(f'values of num_comments: ', values.unique())\n",
    "#\n",
    "# values = df['num_comments']\n",
    "# print(f'values of num_comments: ', values.unique())\n",
    "#\n",
    "# values = df['num_shares']\n",
    "# print(f'values of num_shares: ', values.unique())\n",
    "#\n",
    "# values = df['num_likes']\n",
    "# print(f'values of num_likes: ', values.unique())\n",
    "#\n",
    "# values = df['Column1']\n",
    "# print(f'values Column1: ', values.unique())\n",
    "#\n",
    "# values = df['Column2']\n",
    "# print(f'values Column2: ', values.unique())\n",
    "#\n",
    "# values = df['Column3']\n",
    "# print(f'values Column3: ', values.unique())\n",
    "\n",
    "\n",
    "df = df.drop(['Column1', 'Column2', 'Column3', 'Column4'], axis=1)\n",
    "print(f'columns: ', df.columns)\n",
    "\n",
    "df = pd.get_dummies(df, columns=['status_type'])\n",
    "print(\"After using dummies: \\n\", df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2b436b-8e0a-4c27-88ea-5ba3f38abd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status_published'] = pd.to_datetime(df['status_published'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccfbfe4-0a4c-412f-bab9-7a31db23a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['published_hour'] = df['status_published'].dt.hour\n",
    "df['published_dayofweek'] = df['status_published'].dt.dayofweek\n",
    "df['published_day'] = df['status_published'].dt.day\n",
    "df['published_month'] = df['status_published'].dt.month\n",
    "\n",
    "df = df.drop(labels=['status_published'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8987ca6a-e6b4-45c1-a23b-445ee302157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b8034-5f20-491d-a80d-9587702eb521",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels=['status_id'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8db636-2a1c-43dc-988e-c65b14ba6af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2729c1f-1d6a-4d93-be64-0616261232b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# df['num_reactions'] = preprocessing.normalize([df['num_reactions']])\n",
    "d = preprocessing.normalize(df, axis=0)\n",
    "scaled_df = pd.DataFrame(d, columns=df.columns)\n",
    "\n",
    "scaled_df['num_reactions'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be03ec24-f61c-4074-9378-f359907f9a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ca36b-c581-4924-b09e-7b27e2d3fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb3ab7a-d8ec-4aef-907b-c245fbe915b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "d = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(d, columns=df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf905c4b-fc5b-4244-af79-bb52b28094a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_df\n",
    "# scaled_df.values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5dbca6-f19d-4cdd-8a1a-879e64424c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df['num_reactions'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93033618-d9c5-48a0-a7db-413bb4213385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "403759a0-f909-49ea-aa23-c9c659dbb558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from numpy import linalg as LA\n",
    "\n",
    "def k_means_clustering(data, k, max_iterations=100):    \n",
    "\n",
    "    centroids, _ = create_centroid_cluster_structure(data, k)\n",
    "\n",
    "    nearest_centroid_idx_for_each_point = None\n",
    "    clusters = {}\n",
    "    for iteration in range(max_iterations):\n",
    "        distances_sq = np.sum((data[:, None, :] - centroids[None, :, :])**2, axis=-1)\n",
    "\n",
    "        nearest_centroid_idx_for_each_point = np.argmin(distances_sq, axis=1) # Output: [0 1 2 2 0]\n",
    "        clusters = {}\n",
    "\n",
    "        unique_cluster_idx = np.unique(nearest_centroid_idx_for_each_point)\n",
    "\n",
    "        for idx in unique_cluster_idx:\n",
    "            cluster_data = data[nearest_centroid_idx_for_each_point == idx]\n",
    "            clusters[idx] = cluster_data.tolist()  # Convert back to list for dictionary\n",
    "\n",
    "        for cluster_key in range(len(clusters)):\n",
    "            updated_centroid = np.mean(clusters.get(cluster_key), axis=0)\n",
    "            centroids[cluster_key] = updated_centroid\n",
    "    \n",
    "\n",
    "    return nearest_centroid_idx_for_each_point, centroids \n",
    "\n",
    "def create_centroid_cluster_structure(data, k):\n",
    "    indices_array = np.arange(len(data))\n",
    "    random_indices = np.random.choice(indices_array, size=k, replace=False)\n",
    "\n",
    "    centroids = data[random_indices]\n",
    "    clusters = dict()\n",
    "    \n",
    "    for i in range(k): # < 1 or 2 or 3 \n",
    "        clusters[i] = []\n",
    "    \n",
    "    return centroids, clusters\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45e5909-0fa4-4fe8-a384-7506923a65f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [[1, 2], [4, 5], [2, 2], [5, 5], [7, 7]]\n",
    "\n",
    "points = np.array(points)\n",
    "nearest_centroid_idx_for_each_point, centroids = k_means_clustering(points, k = 3)\n",
    "nearest_centroid_idx_for_each_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71550d27-5808-42e8-869e-2efde779ca4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "points = np.array(scaled_df.values)\n",
    "categorized_points, centroids = k_means_clustering(points, k = 3) # categorized points says that this point corresponds to this centroid \n",
    "\n",
    "# categorized_points\n",
    "# centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e8c8e73-96d9-44cf-81a5-4e97bfded2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key=  [1, 2]\n",
      "key=  [4, 5]\n",
      "key=  [1, 2]\n",
      "key=  [4, 5]\n",
      "key=  [7, 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'[1, 2]': [[1, 2], [2, 2]], '[4, 5]': [[4, 5], [5, 5]], '[7, 7]': [[7, 7]]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def create_centroid_points_structure(points, corresponding_centroid_to_point, centroids):\n",
    "    output = {}\n",
    "    \n",
    "    for centroid in centroids:\n",
    "        output[str(centroid)] = []\n",
    "    \n",
    "    for index, centroid_index in enumerate(corresponding_centroid_to_point):\n",
    "        \n",
    "\n",
    "        point = points[index]\n",
    "\n",
    "        key = str(centroids[centroid_index])\n",
    "        \n",
    "        print('key= ', key)\n",
    "        output[key].append(point)\n",
    "\n",
    "    return output\n",
    "        \n",
    "points = [[1, 2], [4, 5], [2, 2], [5, 5], [7, 7]]\n",
    "centroids = [[1, 2], [4, 5], [7, 7]]\n",
    "corresponding_centroid_to_point = [0, 1, 0, 1, 2]\n",
    "\n",
    "create_centroid_points_structure(points, corresponding_centroid_to_point, centroids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab7bc5-2649-42e0-af42-7d16965c4b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform kmeans on the main dataset\n",
    "points = scaled_df.values\n",
    "k = 3\n",
    "nearest_corresponding_centroid, centroids = k_means_clustering(points, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b3b38-d28b-4e5e-98dc-428588425260",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids\n",
    "# nearest_corresponding_centroid[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed460a7-6923-45e9-a826-b73b85fa49d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_poits_dict = create_centroid_points_structure(points, nearest_corresponding_centroid, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d7c2f1-1fb1-49f8-8b02-c328f24b1e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_poits_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59421f6f-f398-4071-912c-a174aa6b2528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform elbow method\n",
    "import json\n",
    "centroid_points_dict = {'[1, 2]': [[1, 3], [4, 5], [6, 7]],\n",
    "                       '[3, 1]': [[1, 5], [3, 3], [7, 9]],\n",
    "                       '[5, 7]': [[2, 3], [6, 7], [7, 7]]}\n",
    "def calculate_wcss_util(centroid_points_dict):\n",
    "\n",
    "    total_wcss = 0\n",
    "    for key in centroid_points_dict:\n",
    "        points = centroid_points_dict[key]\n",
    "        # centroid = ast.literal_eval(key)  # error\n",
    "        centroid = json.loads(key)\n",
    "\n",
    "        print(f'centroid= ', centroid)\n",
    "        wcss = 0\n",
    "        wcss = np.sum([np.linalg.norm(centroid - np.array(point)) ** 2 for point in points])\n",
    "        print(f'wcss={wcss}')\n",
    "        \n",
    "        total_wcss += wcss        \n",
    "    \n",
    "    return total_wcss\n",
    "\n",
    "def calculate_wcss(points, K=20):\n",
    "    \n",
    "    WCSS = []\n",
    "    for k in range(K):\n",
    "        # perform kmeans\n",
    "        nearest_centroid_index_for_each_point, centroids  = k_means_clustering(points, k + 1)\n",
    "        \n",
    "        # obtain clusters\n",
    "        centroid_points = create_centroid_points_structure(points, nearest_centroid_index_for_each_point, centroids)\n",
    "        # assign a wcss to the current k\n",
    "\n",
    "        print(centroid_points)\n",
    "        \n",
    "        wcss = calculate_wcss_util(centroid_points)\n",
    "        WCSS.append(wcss)\n",
    "    \n",
    "    return WCSS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eced0d9c-8cc7-4f17-8d57-c08c444058cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test WCSS\n",
    "\n",
    "def generate_clustered_points(k):\n",
    "  \n",
    "  n_samples = 200 * k  # Adjust number of points per cluster as needed\n",
    "  means = []\n",
    "  stds = np.random.rand(k)  # Random standard deviations for each cluster\n",
    "\n",
    "  # Generate centers for each cluster\n",
    "  for i in range(k):\n",
    "    means.append(np.random.rand(2) * 10)  # Random centers within a 10x10 area\n",
    "\n",
    "  # Generate points around each center using Gaussian distribution\n",
    "  data = np.zeros((n_samples, 2))\n",
    "  for i in range(k):\n",
    "    data[i * n_samples // k : (i + 1) * n_samples // k] = np.random.normal(means[i], stds[i], size=(n_samples // k, 2))\n",
    "\n",
    "  return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c42b451a-6a0b-451b-87f6-9c43ae2e5960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... existing code to generate points ...\n",
    "\n",
    "# Plot the data points\n",
    "def plot_graph(points):\n",
    "    plt.scatter(points[:, 0], points[:, 1])  # Separate x and y coordinates\n",
    "    \n",
    "    # Optional: Add labels and title\n",
    "    plt.xlabel(\"X-axis\")\n",
    "    plt.ylabel(\"Y-axis\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_elbow_graph(WCSS, K):\n",
    "    plt.plot(Xs, Ys)  # Change scatter to plot for lines\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(\"K\")\n",
    "    plt.ylabel(\"WCSS\")\n",
    "    plt.title(\"Elbow Technique\")\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee5573-9f1c-497e-afb2-a3982f832d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_points = generate_clustered_points(k = 8)\n",
    "plot_graph(sample_points)\n",
    "\n",
    "WCSS = calculate_wcss(sample_points, K=20) # error\n",
    "# Ks = np.arange(K)\n",
    "# print(Ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d345887a-e0a0-4124-b39a-f53122b41522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1, 2.2]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c895f36e-1141-4ae9-9c07-8d8ab22e0785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1, 22]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1.1, 2.2])\n",
    "list([1.1 ,22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84be105c-f81e-4e86-8565-5827646c146b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[2, 2]'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '[2 2]'\n",
    "a.replace(' ', ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5854642a-620d-47ad-8419-61a51dcbc489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "',' in a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf8895-9d06-46bd-be01-32a817c29f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
